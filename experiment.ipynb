{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amiBlH_Mi5y2"
      },
      "source": [
        "Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SRJi9sfimRc",
        "outputId": "ef1ffd94-1a81-4d1b-c662-8d7c5bf9b78b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting nflows\n",
            "  Downloading nflows-0.14.tar.gz (45 kB)\n",
            "\u001b[?25l\r\u001b[K     |███████▏                        | 10 kB 16.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 20 kB 21.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 30 kB 17.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 40 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 45 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from nflows) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from nflows) (1.19.5)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from nflows) (2.6.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from nflows) (1.9.0+cu111)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nflows) (4.62.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->nflows) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->nflows) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->nflows) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->nflows) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->nflows) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->nflows) (0.12.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->nflows) (57.4.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->nflows) (1.41.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->nflows) (0.6.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->nflows) (0.37.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->nflows) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->nflows) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->nflows) (1.35.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->nflows) (3.17.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->nflows) (3.3.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->nflows) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->nflows) (1.0.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->nflows) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->nflows) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->nflows) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->nflows) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->nflows) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->nflows) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->nflows) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->nflows) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->nflows) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->nflows) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->nflows) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->nflows) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->nflows) (3.7.4.3)\n",
            "Building wheels for collected packages: nflows\n",
            "  Building wheel for nflows (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nflows: filename=nflows-0.14-py3-none-any.whl size=53671 sha256=b57a81a8ca11f2d5bb2920ac49683a23558973d7ff09c76750441a07842694bf\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/b6/52/0092eedabce8f7faa35b92522393fbdc1ec5ede99b0ec820d5\n",
            "Successfully built nflows\n",
            "Installing collected packages: nflows\n",
            "Successfully installed nflows-0.14\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import sklearn.datasets as datasets\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "\n",
        "! pip install nflows\n",
        "from nflows.flows.base import Flow\n",
        "from nflows.distributions.normal import StandardNormal\n",
        "from nflows.transforms.base import CompositeTransform\n",
        "from nflows.transforms.autoregressive import MaskedAffineAutoregressiveTransform\n",
        "from nflows.transforms.permutations import ReversePermutation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZ-HjTWTOtij"
      },
      "source": [
        "# MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "SpiZJbzYOzo9"
      },
      "outputs": [],
      "source": [
        "import gzip\n",
        "import pickle\n",
        "\n",
        "def load_data():\n",
        "  f = gzip.open('mnist.pkl.gz', 'rb')\n",
        "\n",
        "  # fix for encoding of pickle\n",
        "  u = pickle._Unpickler(f)\n",
        "  u.encoding = 'latin1'\n",
        "\n",
        "  train_data, validation_data, test_data = u.load()\n",
        "  f.close()\n",
        "\n",
        "  return (train_data, validation_data, test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "IgNSTJfrs_un"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(data, rng, alpha=1.0e-6, logit=False, should_dequantize=True):\n",
        "  \"\"\"\n",
        "  Processes the dataset\n",
        "  \"\"\"\n",
        "  x = dequantize(data[0], rng) if should_dequantize else data[0]  # dequantize pixels\n",
        "  x = logit_transform(x, alpha) if logit else x             # logit\n",
        "  labels = data[1]                                          # numeric labels\n",
        "  encoded_labels = one_hot_encode(labels, 10)               # 1-hot encoded labels\n",
        "  return (x, labels, encoded_labels)\n",
        "\n",
        "def dequantize(x, rng):\n",
        "  \"\"\"\n",
        "  Adds noise to pixels to dequantize them\n",
        "  \"\"\"\n",
        "  return x + rng.rand(*x.shape) / 256.0\n",
        "\n",
        "def logit_transform(x, alpha=1.0e-6):\n",
        "  \"\"\"\n",
        "  Transforms pixel values with logit to reduce the impact of boundary effects\n",
        "  \"\"\"\n",
        "  a = alpha + (1 - 2*alpha) * x\n",
        "  return np.log(a / (1.0 - a))\n",
        "\n",
        "def one_hot_encode(labels, nr_labels):\n",
        "  \"\"\"\n",
        "  Transforms numeric labels to 1-hot encoded labels\n",
        "  \"\"\"\n",
        "  y = np.zeros([labels.size, nr_labels])\n",
        "  y[range(labels.size), labels] = 1\n",
        "  return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5rEcmrk02zT"
      },
      "outputs": [],
      "source": [
        "def load_vectorized_data():\n",
        "  train_data, validation_data, test_data = load_data()\n",
        "  rng = np.random.RandomState(42)\n",
        "  processed_train_data = preprocess_data(train_data, rng, logit=True)\n",
        "  processed_validation_data = preprocess_data(validation_data, rng, logit=True)\n",
        "  processed_test_data = preprocess_data(test_data, rng, logit=True)\n",
        "  return (processed_train_data, processed_validation_data, processed_test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "MWIAnX_Hz5Kx"
      },
      "outputs": [],
      "source": [
        "train_data, validation_data, test_data = load_vectorized_data()\n",
        "\n",
        "train_x = train_data[0]\n",
        "train_labels = train_data[1]\n",
        "train_y = train_data[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gaBoZr1t296L"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "MAF-MNIST.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
