{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MAF-MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amiBlH_Mi5y2"
      },
      "source": [
        "Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SRJi9sfimRc",
        "outputId": "86f2ddfd-23da-42f1-bc63-8367ba0d2c86"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import sklearn.datasets as datasets\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "! pip install nflows\n",
        "from nflows.flows.base import Flow\n",
        "from nflows.distributions.normal import StandardNormal\n",
        "from nflows.transforms.base import CompositeTransform\n",
        "from nflows.transforms.autoregressive import MaskedAffineAutoregressiveTransform\n",
        "from nflows.transforms.permutations import ReversePermutation"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nflows in /usr/local/lib/python3.7/dist-packages (0.14)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nflows) (4.62.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from nflows) (1.19.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from nflows) (1.9.0+cu111)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from nflows) (2.6.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from nflows) (3.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->nflows) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->nflows) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->nflows) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->nflows) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->nflows) (1.15.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->nflows) (3.3.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->nflows) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->nflows) (2.23.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->nflows) (1.41.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->nflows) (1.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->nflows) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->nflows) (0.6.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->nflows) (0.37.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->nflows) (1.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->nflows) (0.12.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->nflows) (0.4.6)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->nflows) (3.17.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->nflows) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->nflows) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->nflows) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->nflows) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->nflows) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->nflows) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->nflows) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->nflows) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->nflows) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->nflows) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->nflows) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->nflows) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->nflows) (3.7.4.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZ-HjTWTOtij"
      },
      "source": [
        "# MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpiZJbzYOzo9"
      },
      "source": [
        "import gzip\n",
        "import pickle\n",
        "\n",
        "def load_data():\n",
        "  f = gzip.open('mnist.pkl.gz', 'rb')\n",
        "\n",
        "  # fix for encoding of pickle\n",
        "  u = pickle._Unpickler(f)\n",
        "  u.encoding = 'latin1'\n",
        "\n",
        "  train_data, validation_data, test_data = u.load()\n",
        "  f.close()\n",
        "\n",
        "  return (train_data, validation_data, test_data)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgNSTJfrs_un"
      },
      "source": [
        "def preprocess_data(data, rng, alpha=1.0e-6, logit=False, should_dequantize=True):\n",
        "  \"\"\"\n",
        "  Processes the dataset\n",
        "  \"\"\"\n",
        "  x = dequantize(data[0], rng) if should_dequantize else data[0]  # dequantize pixels\n",
        "  x = logit_transform(x, alpha) if logit else x                   # logit\n",
        "  labels = data[1]                                                # numeric labels\n",
        "  encoded_labels = one_hot_encode(labels, 10)                     # 1-hot encoded labels\n",
        "  return (x, labels, encoded_labels)\n",
        "\n",
        "def dequantize(x, rng):\n",
        "  \"\"\"\n",
        "  Adds noise to pixels to dequantize them\n",
        "  \"\"\"\n",
        "  return x + rng.rand(*x.shape) / 256.0\n",
        "\n",
        "def logit_transform(x, alpha=1.0e-6):\n",
        "  \"\"\"\n",
        "  Transforms pixel values with logit to reduce the impact of boundary effects\n",
        "  \"\"\"\n",
        "  a = alpha + (1 - 2*alpha) * x\n",
        "  return np.log(a / (1.0 - a))\n",
        "\n",
        "def one_hot_encode(labels, nr_labels):\n",
        "  \"\"\"\n",
        "  Transforms numeric labels to 1-hot encoded labels\n",
        "  \"\"\"\n",
        "  y = np.zeros([labels.size, nr_labels])\n",
        "  y[range(labels.size), labels] = 1\n",
        "  return y"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5rEcmrk02zT"
      },
      "source": [
        "def load_vectorized_data():\n",
        "  train_data, validation_data, test_data = load_data()\n",
        "  rng = np.random.RandomState(42)\n",
        "  processed_train_data = preprocess_data(train_data, rng, logit=True)\n",
        "  processed_validation_data = preprocess_data(validation_data, rng, logit=True)\n",
        "  processed_test_data = preprocess_data(test_data, rng, logit=True)\n",
        "  return (processed_train_data, processed_validation_data, processed_test_data)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWIAnX_Hz5Kx"
      },
      "source": [
        "train_data, validation_data, test_data = load_vectorized_data()\n",
        "\n",
        "train_x = train_data[0]\n",
        "train_labels = train_data[1]\n",
        "train_y = train_data[2]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaBoZr1t296L"
      },
      "source": [
        "def build_flow(num_dim, hidden_features=1024, layers=5, batch_norm=False):\n",
        "  base_dist = StandardNormal(shape=[num_dim])\n",
        "  transforms = []\n",
        "  for _ in range(layers):\n",
        "    transforms.append(ReversePermutation(features=num_dim))\n",
        "    transforms.append(MaskedAffineAutoregressiveTransform(features=num_dim,\n",
        "                                                          hidden_features=hidden_features,\n",
        "                                                          use_batch_norm=batch_norm))\n",
        "  transform = CompositeTransform(transforms)\n",
        "  return Flow(transform, base_dist)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASq4ewaqXnIv"
      },
      "source": [
        "def train(x, num_iter, train_loader, weight_decay=None):\n",
        "  num_dim = x.shape[1]\n",
        "  flow = build_flow(num_dim)\n",
        "  optimizer = optim.Adam(flow.parameters(),\n",
        "                         weight_decay=0 if weight_decay is None else weight_decay)\n",
        "\n",
        "  x = x.clone().detach()\n",
        "\n",
        "  i = 1\n",
        "  for x, y, _ in train_loader:\n",
        "    optimizer.zero_grad()\n",
        "    loss = -flow.log_prob(inputs=x).mean()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  # for iter in range(1, num_iter + 1):\n",
        "  #   optimizer.zero_grad()\n",
        "  #   loss = -flow.log_prob(inputs=x).mean()\n",
        "  #   loss.backward()\n",
        "  #   optimizer.step()\n",
        "\n",
        "    if i % 100 == 0:\n",
        "      print('iteration {}, loss {:.5f}'.format(i, loss.detach().numpy()))\n",
        "    i+=1\n",
        "\n",
        "  return flow\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPzUArpZAWPQ"
      },
      "source": [
        "# train_x = torch.tensor(train_x, dtype=torch.float32)\n",
        "# train_y = torch.tensor(train_y, dtype=torch.float32)\n",
        "# train_labels = torch.tensor(train_labels, dtype=torch.float32)\n",
        "trainset = TensorDataset(train_x.clone().detach(), train_y.clone().detach(), train_labels.clone().detach())\n",
        "trainloader = DataLoader(trainset, batch_size=100, shuffle=True, num_workers=0)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_WhSx9yYZjf",
        "outputId": "8efd1f7c-c7f7-4c4b-b893-6280291dd638"
      },
      "source": [
        "epochs = 30\n",
        "for epoch in range(1, epochs + 1):\n",
        "  print('Epoch {}'.format(epoch))\n",
        "  model = train(train_x, 5000, trainloader)\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "iteration 100, loss 1950.92798\n",
            "iteration 200, loss 1608.98401\n",
            "iteration 300, loss 1511.99036\n",
            "iteration 400, loss 1469.01550\n",
            "iteration 500, loss 1425.98669\n",
            "Epoch 2\n",
            "iteration 100, loss 6136.89648\n",
            "iteration 200, loss 3037.57788\n",
            "iteration 300, loss 2683.40063\n",
            "iteration 400, loss 2422.02759\n",
            "iteration 500, loss 4343.75732\n",
            "Epoch 3\n",
            "iteration 100, loss 2060.49902\n",
            "iteration 200, loss 1744.64954\n",
            "iteration 300, loss 1590.92078\n",
            "iteration 400, loss 1550.77344\n",
            "iteration 500, loss 1480.35083\n",
            "Epoch 4\n",
            "iteration 100, loss 6548.99756\n",
            "iteration 200, loss 3573.33228\n",
            "iteration 300, loss 4737.01514\n",
            "iteration 400, loss 4105.22754\n",
            "iteration 500, loss 3695.04614\n",
            "Epoch 5\n",
            "iteration 100, loss 2219.29370\n",
            "iteration 200, loss 1782.40552\n",
            "iteration 300, loss 1665.16370\n",
            "iteration 400, loss 1561.95850\n",
            "iteration 500, loss 1523.92419\n",
            "Epoch 6\n",
            "iteration 100, loss 2602.58765\n",
            "iteration 200, loss 2059.84717\n",
            "iteration 300, loss 1863.29675\n",
            "iteration 400, loss 1734.94177\n",
            "iteration 500, loss 1653.68713\n",
            "Epoch 7\n",
            "iteration 100, loss 1937.08435\n",
            "iteration 200, loss 1609.46240\n",
            "iteration 300, loss 1508.12280\n",
            "iteration 400, loss 1464.36316\n",
            "iteration 500, loss 1426.80847\n",
            "Epoch 8\n",
            "iteration 100, loss nan\n",
            "iteration 200, loss nan\n",
            "iteration 300, loss nan\n",
            "iteration 400, loss nan\n",
            "iteration 500, loss nan\n",
            "Epoch 9\n",
            "iteration 100, loss 2378.95459\n",
            "iteration 200, loss 1968.18311\n",
            "iteration 300, loss 1782.90015\n",
            "iteration 400, loss 1640.67737\n",
            "iteration 500, loss 1568.71021\n",
            "Epoch 10\n",
            "iteration 100, loss 2095.50024\n",
            "iteration 200, loss 1711.33350\n",
            "iteration 300, loss 1608.65271\n",
            "iteration 400, loss 1542.12109\n",
            "iteration 500, loss 1482.38293\n",
            "Epoch 11\n",
            "iteration 100, loss 2238.74927\n",
            "iteration 200, loss 1908.81250\n",
            "iteration 300, loss 1743.37256\n",
            "iteration 400, loss 1618.06531\n",
            "iteration 500, loss 1577.05286\n",
            "Epoch 12\n",
            "iteration 100, loss 4192.33936\n",
            "iteration 200, loss 2627.49683\n",
            "iteration 300, loss 2251.75317\n",
            "iteration 400, loss 2077.73462\n",
            "iteration 500, loss 2015.74536\n",
            "Epoch 13\n",
            "iteration 100, loss 2249.63428\n",
            "iteration 200, loss 1911.49878\n",
            "iteration 300, loss 1755.05286\n",
            "iteration 400, loss 1649.21338\n",
            "iteration 500, loss 1583.18018\n",
            "Epoch 14\n",
            "iteration 100, loss 913205106138299519853395968.00000\n",
            "iteration 200, loss 855798469646033921033371648.00000\n",
            "iteration 300, loss 676040777818861632753762304.00000\n",
            "iteration 400, loss 970296081945975800826167296.00000\n",
            "iteration 500, loss 911617136621458306812084224.00000\n",
            "Epoch 15\n",
            "iteration 100, loss 5400.46240\n",
            "iteration 200, loss 3517.55762\n",
            "iteration 300, loss 2920.80713\n",
            "iteration 400, loss 2628.02759\n",
            "iteration 500, loss 2388.90552\n",
            "Epoch 16\n",
            "iteration 100, loss 2658.53247\n",
            "iteration 200, loss 2261.60693\n",
            "iteration 300, loss 2006.44702\n",
            "iteration 400, loss 1880.54480\n",
            "iteration 500, loss 1801.20935\n",
            "Epoch 17\n",
            "iteration 100, loss 2735.67114\n",
            "iteration 200, loss 2163.40942\n",
            "iteration 300, loss 1999.76282\n",
            "iteration 400, loss 1912.91418\n",
            "iteration 500, loss 1856.72034\n",
            "Epoch 18\n",
            "iteration 100, loss 2608.72095\n",
            "iteration 200, loss 2196.69873\n",
            "iteration 300, loss 1989.10815\n",
            "iteration 400, loss 1870.09314\n",
            "iteration 500, loss 1783.59937\n",
            "Epoch 19\n",
            "iteration 100, loss 2685.58716\n",
            "iteration 200, loss 2038.50745\n",
            "iteration 300, loss 1858.79736\n",
            "iteration 400, loss 1782.09644\n",
            "iteration 500, loss 1706.55249\n",
            "Epoch 20\n",
            "iteration 100, loss 2161.28101\n",
            "iteration 200, loss 1825.57202\n",
            "iteration 300, loss 1684.76831\n",
            "iteration 400, loss 1590.82849\n",
            "iteration 500, loss 1530.63989\n",
            "Epoch 21\n",
            "iteration 100, loss 1933.59058\n",
            "iteration 200, loss 1684.01343\n",
            "iteration 300, loss 1572.06604\n",
            "iteration 400, loss 12497198717964341626273792.00000\n",
            "iteration 500, loss 5850014218713253193711616.00000\n",
            "Epoch 22\n",
            "iteration 100, loss 2566.49463\n",
            "iteration 200, loss 2069.68530\n",
            "iteration 300, loss 1877.41724\n",
            "iteration 400, loss 1772.75708\n",
            "iteration 500, loss 1682.39124\n",
            "Epoch 23\n",
            "iteration 100, loss 3285.60840\n",
            "iteration 200, loss 2496.53711\n",
            "iteration 300, loss 2185.52124\n",
            "iteration 400, loss 1993.73975\n",
            "iteration 500, loss 1910.39221\n",
            "Epoch 24\n",
            "iteration 100, loss 3527.87012\n",
            "iteration 200, loss 2449.23584\n",
            "iteration 300, loss 2223.95801\n",
            "iteration 400, loss 2157.97729\n",
            "iteration 500, loss 2092.77271\n",
            "Epoch 25\n",
            "iteration 100, loss 2146.56519\n",
            "iteration 200, loss 1844.93909\n",
            "iteration 300, loss 1743.05029\n",
            "iteration 400, loss 1523.77100\n",
            "iteration 500, loss 1497.51599\n",
            "Epoch 26\n",
            "iteration 100, loss 2921.65308\n",
            "iteration 200, loss 2206.39600\n",
            "iteration 300, loss 1954.11340\n",
            "iteration 400, loss 1851.65955\n",
            "iteration 500, loss 1768.35217\n",
            "Epoch 27\n",
            "iteration 100, loss 3777.06348\n",
            "iteration 200, loss 2809.14380\n",
            "iteration 300, loss 2493.12427\n",
            "iteration 400, loss 2331.87329\n",
            "iteration 500, loss 2219.63989\n",
            "Epoch 28\n",
            "iteration 100, loss 2173.39160\n",
            "iteration 200, loss 1835.20374\n",
            "iteration 300, loss 1711.19861\n",
            "iteration 400, loss 1630.71545\n",
            "iteration 500, loss 1563.84302\n",
            "Epoch 29\n",
            "iteration 100, loss 2097.60938\n",
            "iteration 200, loss 1672.04456\n",
            "iteration 300, loss 1558.98608\n",
            "iteration 400, loss 1473.32043\n",
            "iteration 500, loss 1462.43506\n",
            "Epoch 30\n",
            "iteration 100, loss 2078.42847\n",
            "iteration 200, loss 1752.21167\n",
            "iteration 300, loss 1613.10388\n",
            "iteration 400, loss 1555.05005\n",
            "iteration 500, loss 1500.68750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjY4bDKr6ZkM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}